{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "from cv2 import cv2\n",
    "from glob import glob\n",
    "from mrcnn import utils\n",
    "from samples.coco import coco\n",
    "from threading import Thread\n",
    "from skimage.util import img_as_float, img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\envs\\ta\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check model, download if not exist\n",
    "if not os.path.exists('mask_rcnn_coco.h5'):\n",
    "    utils.download_trained_weights('mask_rcnn_coco.h5')\n",
    "\n",
    "#create config\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "#modelling\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir='logs/', config=config)\n",
    "\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True)\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn = modellib.build_rpn_model(config.RPN_ANCHOR_STRIDE, len(config.RPN_ANCHOR_RATIOS), config.TOP_DOWN_PYRAMID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_rpn_feature_map (InputLay (None, None, None, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv_shared (Conv2D)        (None, None, None, 5 1180160     input_rpn_feature_map[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_raw (Conv2D)          (None, None, None, 6 3078        rpn_conv_shared[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, 2)      0           rpn_class_raw[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_bbox_pred (Conv2D)          (None, None, None, 1 6156        rpn_conv_shared[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_xxx (Activation)      (None, None, 2)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None, 4)      0           rpn_bbox_pred[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,189,394\n",
      "Trainable params: 1,189,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rpn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(rpn, to_file='rpn_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1080, 1920, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1920.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-b156f1028093>\", line 7, in worker\n",
      "    master = func([frame], verbose=1)\n",
      "  File \"D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py\", line 2524, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3473, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3410, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1505, in _make_callable_from_options\n",
      "    return BaseSession._Callable(self, callable_options)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1460, in __init__\n",
      "    session._session, options_ptr)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor input_image_1:0, specified in either feed_devices or fetch_devices was not found in the Graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1080, 1920, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1920.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-b156f1028093>\", line 7, in worker\n",
      "    master = func([frame], verbose=1)\n",
      "  File \"D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py\", line 2524, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3473, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3410, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1505, in _make_callable_from_options\n",
      "    return BaseSession._Callable(self, callable_options)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1460, in __init__\n",
      "    session._session, options_ptr)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor input_image_1:0, specified in either feed_devices or fetch_devices was not found in the Graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1080, 1920, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1920.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-b156f1028093>\", line 7, in worker\n",
      "    master = func([frame], verbose=1)\n",
      "  File \"D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py\", line 2524, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3473, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3410, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1505, in _make_callable_from_options\n",
      "    return BaseSession._Callable(self, callable_options)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1460, in __init__\n",
      "    session._session, options_ptr)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor input_image_1:0, specified in either feed_devices or fetch_devices was not found in the Graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1080, 1920, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1920.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-b156f1028093>\", line 7, in worker\n",
      "    master = func([frame], verbose=1)\n",
      "  File \"D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py\", line 2524, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3473, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3410, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1505, in _make_callable_from_options\n",
      "    return BaseSession._Callable(self, callable_options)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1460, in __init__\n",
      "    session._session, options_ptr)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor input_image_1:0, specified in either feed_devices or fetch_devices was not found in the Graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1080, 1920, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1920.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-b156f1028093>\", line 7, in worker\n",
      "    master = func([frame], verbose=1)\n",
      "  File \"D:\\kuliah\\TA\\ta_mask_rcnn\\mrcnn\\model.py\", line 2524, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3473, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3410, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1505, in _make_callable_from_options\n",
      "    return BaseSession._Callable(self, callable_options)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1460, in __init__\n",
      "    session._session, options_ptr)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor input_image_1:0, specified in either feed_devices or fetch_devices was not found in the Graph\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b156f1028093>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'video'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output/{}_{}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mcapturer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = glob('videos/*')\n",
    "master = None\n",
    "\n",
    "def worker(frame, func):\n",
    "    global master\n",
    "    now = time.time()\n",
    "    master = func([frame], verbose=1)\n",
    "    end = time.time() - now\n",
    "    master[0]['time'] = end\n",
    "\n",
    "for video in files:\n",
    "    name = video.split('\\\\')[1]\n",
    "    name = name.split('.')[0]\n",
    "    capturer = cv2.VideoCapture(video)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        ret, frame = capturer.read()\n",
    "        time.sleep(1/30)\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # now = time.time()\n",
    "        # master = model.detect([frame])\n",
    "        # end = time.time() - now\n",
    "        # master[0]['time'] = end\n",
    "\n",
    "        if counter == 1:\n",
    "            now = time.time()\n",
    "            master = model.detect([frame])\n",
    "            end = time.time() - now\n",
    "            master[0]['time'] = end\n",
    "\n",
    "        if counter % 20 == 0:\n",
    "            t = Thread(target=worker, args=(frame, model.detect))\n",
    "            t.start()\n",
    "\n",
    "        if master != None:\n",
    "            result = master[0]\n",
    "            for i in range(len(result['rois'])):\n",
    "                y1, x1, y2, x2 = result['rois'][i]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "                cv2.putText(frame, class_names[result['class_ids'][i]], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                cv2.putText(frame, str(result['time']), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "        cv2.imshow('video', frame)\n",
    "        cv2.waitKey(1)\n",
    "        cv2.imwrite('output/{}_{}.png'.format(counter, name), frame)\n",
    "\n",
    "    capturer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
